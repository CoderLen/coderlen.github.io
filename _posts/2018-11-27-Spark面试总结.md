---
layout:     post
title:      "Spark面试总结"
date:       2018-11-23 17:19:00
author:     "CoderLen"
header-img: "img/bigdata.jpg"
tags:
    - 面试
    - 大数据
    - Spark
---

### Spark面试总结

1. RDD是什么？有什么特性？

   RDD是弹性分布式数据集，是Spark中最基本的数据抽象，它代表一个不可变、可分区、里面元素可并行计算的集合。弹性表示RDD中的数据可以存储在内存或者是磁盘，RDD的分区是可以改变的。

   五大特性：

    	1. 一个分区列表，RDD中数据都存在一个分区列表里面；
    	2. 作用在每一个分区中的函数
    	3. 一个RDD依赖于其他RDD，也就是血统
    	4. 可选的，针对kv类型的RDD才有的特性
    	5. 可选的，RDD的每个分区在计算时会选择最佳的计算位置；

2. RDD有哪些缺陷？

   1. 不支持细粒度的写和更新操作(如网络爬虫)，spark写数据是粗粒度的，所谓粗粒度就是批量写入数据。
   2. 不支持增量迭代计算，Flink支持；

3. Spark怎么划分Job，Stage, Task?

   Spark按action算子划分Job，例如count(), foreach()，reduce(), collect()等；

   按宽依赖/action划分stage，有ShuffleStage，ResultStage

   task是spark的最小执行单元，跟partition有关。

4. 宽依赖，窄依赖

   - 宽依赖：指多个子RDD的Partition会依赖同一个父RDD的Partition
   - 窄依赖：每一个父RDD的Partition最多被子RDD的一个Partition使用；

5. cache()和persist()方法的区别？

   1. cache和persist都是用于将一个RDD进行缓存，这样在之后的使用就不需要重新计算了，可以节省程序运行时间。
   2. cache()内部调用了persist()，默认缓存级别是MEMORY_ONLY。而persist()可以根据情况设置其它的缓存级别；
   3. 

6. cache()后面能不能接其它算子，它是不是action操作；

   cache可以接其它算子，但是接了算子之后，起不到缓存应有的效果，因为会重新触发cache。cache不是action算子。

7. repartition()和coalesce()的区别？

8. hadoop和spark的shuffle的相同之处和差异？

   |                        | MapReduce                                         | Spark                                                        |
   | ---------------------- | ------------------------------------------------- | ------------------------------------------------------------ |
   | collect                | 在内存中构造了一块数据结构用于map输出的缓冲       | 没有在内存中构造一块数据结构用于map输出的缓冲，而是直接把输出写到磁盘文件 |
   | sort                   | map输出的数据有排序                               | map输出的数据没有排序                                        |
   | merge                  | 对磁盘上的多个spill文件最后进行合并成一个输出文件 | 在map端没有merge过程，在输出时直接是对应一个reduce的数据写到一个文件中，这些文件同时存在并发写，最后不需要合并成一个 |
   | copy框架               | jetty                                             | netty或者直接socket流                                        |
   | 对于本节点上的文件     | 仍然是通过网络框架拖取数据                        | 不通过网络框架，对于在本节点上的map输出文件，采用本地读取的方式 |
   | copy过来的数据存放位置 | 先放在内存，内存放不下时写到磁盘                  | 一种方式全部放在内存；另一种方式先放在内存                   |
   | merge sort             | 最后会对磁盘文件和内存中的数据进行合并排序        | 对于采用另一种方式时也会有合并排序的过程                     |

9. cogroup rdd的实现原理，在什么场景下用过这个rdd？

   cogroup将多个RDD中同一个Key对应的Value组合到一起。最多可以组合四个RDD。

10. spark master ha主从切换的过程不会影响集群已有的作业运行，为什么？

    因为程序在运行之前，已经申请过资源了，剩下就是driver和executors通讯，不需要和master通讯。

11. driver的功能是什么？

    1. 一个Spark作业运行时包括一个Driver进程，也是作业的主进程，具有main函数，并且有SparkContext实例，是程序的入口点；
    2. 负责向集群申请资源，向master注册信息，负责作业的调度，负责作业的解析，生成stage并调度task到executor上，包括DAGScheduler，TaskScheduler;

12. spark中，worker的主要作用是什么？

    管理当前节点内存，CPU资源，接收master分配过来的资源指令，通过ExecutorRunner启动程序分配任务。需要注意的是：

    1. worker会不会汇报当前信息给master，worker心跳给master主要有workid，它不会发送资源信息以心跳的方式给master，master分配的时候就知道worker，只有出现故障时才会发送资源。
    2. worker不会运行代码，具体运行的是Executor。







### 参考

1. <a href="http://www.cnblogs.com/jxhd1/p/6528540.html">Spark的Shuffle过程介绍</a>