### Kafka 面试总结

1. Kafka三个基本概念

2. Kafka数据传输的事务定义有哪三种？

   数据传输的事务定义通常有以下三种定义：

   - 最多一次：消息不会被重复发送，最多被传输一次，但也有可能一次不传输
   - 最少一次：消息不会被漏发送，最少被传输一次，但也有可能被重复传输；
   - 精确的一次（Exactly Once）：不会漏传输也不会重复传输，每个消息都被传输一次而且仅仅被传输一次，这是大家所期望的。

3. Kafka判断一个节点是否还存活的两个条件

   1. 节点必须可以维护和ZK的连接，ZK通过心跳机制检查每个节点的连接
   2. 如果节点是follower，他必须能及时的同步Leader的写操作，延时不能太久。

4. Kafka Produce数据生产流程解析

   在Producer Api里面，我们需要指定一些Properties配置中，其中包括bootstrap-servers。Kafka如何通过这些servers拿到topic的metadata信息，获得对应的Leader所在的服务器，建立连接的？

5. Kafka Consumer数据消费流程解析

6. Kafka Producer是否直接将数据发送到broker的leader上？

   producer直接将数据发送到broker的leader，不需要在多个节点进行分发，为了帮助producer做到这一点，所有的kafka节点都可以及时的高志哪些节点是活动的，目标topic目标分区的leader在哪。这样producer就可以直接将消息发送到目的地了。

7. Kafka Consumer是否可以消费指定的分区消息？

   consumer消费消息时，向broker发出“fetch”请求去消费特定分区的消息，consumer指定消息在日志中的偏移量(offset)，就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的。

8. Kafka消息采用Pull模式还是Push模式？

   Kafka遵循了一种大部分消息系统共同的传统设计：producer将消息推送到broker，consumer从broker拉取消息。

   Pull模式可以让consumer自己控制消费速率，防止broker推送的速率远大于consumer消费的速率时，consumer容易崩溃。

   Pull模式还可以让consumer自己决定是否批量从broker上拉取数据。

   Pull模式有个问题就是，如果没有数据可消费了，consumer会不断在循环中轮询，直到新消息到达。

9. kafka的ack机制

   request.required.acks有三个值0，1，-1

   0：生产者不会等待broker的ack，这个延迟最低但是存储的保证最弱，当server挂掉的时候就会丢数据

   1：服务l端会等待ack值，leader副本确认接收到消息后发送ack但是如果leader挂掉后，它不保证是否复制完成新leader也会导致数据丢失；

   -1：同样在1的基础上，服务端会等待所有的follower的副本受到数据后才会受到leader发出的ack，这样数据不会丢失。

10. Kafka如何保证高并发的，Kafka零拷贝，具体怎么做的

    - Kafka如何保证高并发的？

      - Kafka在磁盘上只做磁盘顺序读写IO，顺序读写IO极快，跟内存读写相差无几。
      - Kafka重度依赖底层操作系统提供的PageCache功能。
      - Partition是Kafka可以很好地横向扩展和提供高并发处理以及实现Replication的基础。
      - Zero Copy

    - Kafka零拷贝？

      ​	Kafka设计基本观点是认为数据时时刻刻都在流动，虽然数据在磁盘中，但是因为是基于内核进行交换，获得了数据近乎是存储在内存中的速度，没必要存放在用户空间。

      ​	一般应用程序有一个buffer空间在用户空间，来自于网络或者磁盘，无论来自网络或者磁盘，都需要通过内核，也就是说内核中也要有buffer。

       1. 磁盘到内核

       2. 内核到应用程序buffer写数据时

       3. 应用程序buffer写到内核buffer

       4. 内核buffer写到磁盘。

          这个过程多了两次拷贝，kafka本身因为不处理数据，所以没必要把数据存放到应用程序的buffer中。所以搞了个基于内核的数据存储和传输，使用sendfile机制，直接基于内核kernel处理。也就是说数据立即写入到文件系统的持久化日志中，不是先写缓存中，再flush到磁盘中。也就是说，数据过来的时候，是传输在os kernel的页面缓存中，由os刷新到磁盘中。在os采用sendfile机制，os可以从页面缓存一步发送数据到网络中，同时，kafka支持gzip和snappy对数据进行压缩，这个对传输数据至关重要。

11. Kafka存储模型和网络模型

    - 存储模型

      kafka在磁盘中的存储结构是topic-partition-record的树状目录结构的。

    - 网络模型

      kafka基于高吞吐率和效率考虑，并没有使用第三方网络框架，而是自己基于java nio封装的。

12. Kafka复制机制，分区多副本机制

    - 复制机制

      kafka的复制是针对分区的，当producer发送一个消息的时候，它会选择一个分区，然后将消息发送给这个分区的leader，其他复制的broker会拉取这个消息，一旦消息被拉取过来后，slave会发送ack给master，这时候master才commit这个log。

      这个过程中producer有两个选择，一是等所有副本都拉取成功producer才收到写入成功的respose，二是等leader写入成功就得到成功的response。第一个可以确保在异常情况下不丢消息，但是latency就下来了。后面一种latency就提高了很多，但是一旦有异常情况，slave还没有来得及拉取到最新的消息leader就挂了，这种情况就有可能丢消息了。

      kafka引入了isr的概念，ISR是in-sync replicas的简写。ISR的副本保持和leader的同步，当然leader本身也在isr中。

13. 如何指定offset读取数据？

    可以通过consumer.seek(partition, offset)方法来指定offset消费

14. kafka的high-level和low-level api的区别？

    Low-level api也就是Simple Consumer APi，实际上非常复杂。

    - High Level Api

      屏蔽了每个topic的每个partition的offset管理（自动读取zookeeper中该consumer group的last offset）、Broker失败转移以及增减partition，consumer时的负载均衡（Kafka自动进行负载均衡）。

      如果consumer比partition多，是浪费，一个partition上是不允许并发的，所以consumer数不要大于partition数。

    - Low Level Api

      - Api控制更灵活，例如消息重复读取，消息offset跳读，Exactly Once原语
      - Api更复杂，offset不再透明，需要自己管理，broker自动失败转移需要处理，增加consumer，partition，broker需要自己做负载均衡。
      - 


