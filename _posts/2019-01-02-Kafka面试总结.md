### Kafka 面试总结

1. Kafka三个基本概念

2. Kafka数据传输的事务定义有哪三种？

   数据传输的事务定义通常有以下三种定义：

   - 最多一次：消息不会被重复发送，最多被传输一次，但也有可能一次不传输
   - 最少一次：消息不会被漏发送，最少被传输一次，但也有可能被重复传输；
   - 精确的一次（Exactly Once）：不会漏传输也不会重复传输，每个消息都被传输一次而且仅仅被传输一次，这是大家所期望的。

3. Kafka判断一个节点是否还存活的两个条件

   1. 节点必须可以维护和ZK的连接，ZK通过心跳机制检查每个节点的连接
   2. 如果节点是follower，他必须能及时的同步Leader的写操作，延时不能太久。

4. Kafka Produce数据生产流程解析

   在Producer Api里面，我们需要指定一些Properties配置中，其中包括bootstrap-servers。Kafka如何通过这些servers拿到topic的metadata信息，获得对应的Leader所在的服务器，建立连接的？

5. Kafka Consumer数据消费流程解析

6. Kafka Producer是否直接将数据发送到broker的leader上？

   producer直接将数据发送到broker的leader，不需要在多个节点进行分发，为了帮助producer做到这一点，所有的kafka节点都可以及时的高志哪些节点是活动的，目标topic目标分区的leader在哪。这样producer就可以直接将消息发送到目的地了。

7. Kafka Consumer是否可以消费指定的分区消息？

   consumer消费消息时，向broker发出“fetch”请求去消费特定分区的消息，consumer指定消息在日志中的偏移量(offset)，就可以消费从这个位置开始的消息，customer拥有了offset的控制权，可以向后回滚去重新消费之前的消息，这是很有意义的。

8. Kafka消息采用Pull模式还是Push模式？

   Kafka遵循了一种大部分消息系统共同的传统设计：producer将消息推送到broker，consumer从broker拉取消息。

   Pull模式可以让consumer自己控制消费速率，防止broker推送的速率远大于consumer消费的速率时，consumer容易崩溃。

   Pull模式还可以让consumer自己决定是否批量从broker上拉取数据。

   Pull模式有个问题就是，如果没有数据可消费了，consumer会不断在循环中轮询，直到新消息到达。

9. kafka的ack机制

   request.required.acks有三个值0，1，-1

   0：生产者不会等待broker的ack，这个延迟最低但是存储的保证最弱，当server挂掉的时候就会丢数据

   1：服务l端会等待ack值，leader副本确认接收到消息后发送ack但是如果leader挂掉后，它不保证是否复制完成新leader也会导致数据丢失；

   -1：同样在1的基础上，服务端会等待所有的follower的副本受到数据后才会受到leader发出的ack，这样数据不会丢失。

10. 